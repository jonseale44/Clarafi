# HYBRID REALTIME + ASSISTANT VOICE WORKFLOW

## ðŸš¨ IMMEDIATE TASK: Replace Existing Voice Features with Modern APIs

You are working on an advanced medical documentation platform that already has a complete voice workflow interface. Your task is to **REPLACE** the existing voice transcription and AI processing features with a modern hybrid system that combines OpenAI Realtime API for live transcription with OpenAI Assistants for intelligent suggestions.

**EXISTING FEATURES TO REPLACE:**
- Current "Start Recording" button and real-time transcription system
- Existing "GPT Suggestions" that appear during recording  
- Current SOAP note generation after recording ends
- Existing "Draft Orders" creation system
- Current "CPT Codes & Diagnoses" generation

**THE INTERFACE IS ALREADY BUILT** - you need to upgrade the underlying API integrations to use modern OpenAI services while maintaining the exact same user experience.

---

## REFERENCE PATTERNS FROM PREVIOUS IMPLEMENTATION

The previous system had working Realtime API patterns that you should adapt for the current platform:

### **WebSocket Client Architecture**
```typescript
// Current working WebSocket connection (from WebSocketClient.ts)
const ws = new WebSocket("wss://api.openai.com/v1/realtime", [
  "realtime",
  "openai-beta.realtime-v1",
]);

// Critical: Headers handled by backend proxy for security
// Uses 24kHz PCM16 audio format that works reliably in Replit

class WebSocketClient {
  private ws: WebSocket | null = null;
  private patientChartsSent: Set<string> = new Set();
  
  async init() {
    // Your current working initialization that handles Replit iframe environment
    // Includes microphone permission handling for Replit security context
  }
  
  async appendAudio(audioBlob: ArrayBuffer) {
    // Current working audio streaming that maintains connection stability
  }
}
```

### **Audio Processing (WORKING IMPLEMENTATION)**
```typescript
// From AudioRecorder.tsx - this audio processing works perfectly in Replit
const stream = await navigator.mediaDevices.getUserMedia({
  audio: {
    echoCancellation: true,
    noiseSuppression: true,
    autoGainControl: true,
    channelCount: 1,
    sampleRate: 24000,  // Critical: matches OpenAI requirements
    sampleSize: 16,
  },
});

// Force AudioContext to match the pcm16 requirement (24kHz)
const context = new AudioContext({ sampleRate: 24000 });
const source = context.createMediaStreamSource(stream);
const bufferSize = 4096; // Default size that works well across browsers
const processor = context.createScriptProcessor(bufferSize, 1, 1);

processor.onaudioprocess = async (e) => {
  const inputData = e.inputBuffer.getChannelData(0);
  const blob = processAudioData(inputData, context.sampleRate, 1);
  await client.appendAudio(blob);
};
```

### **Replit-Specific Security Handling**
```typescript
// Critical for Replit iframe environment - your current working solution
function isReplitIframe(): boolean {
  return window.self !== window.top && 
         (window.location.hostname.includes('replit') || 
          window.location.hostname.includes('repl.co'));
}

// Microphone permission handling that works in Replit
if (isReplitIframe()) {
  try {
    fetch("/api/microphone-permission")
      .then((response) => response.json())
      .then((data) => console.log("Microphone permissions response:", data))
      .catch((error) => console.error("Error fetching microphone permissions:", error));
  } catch (permError) {
    console.error("Error with permissions request:", permError);
  }
}
```

---

## NEW HYBRID ARCHITECTURE STRATEGY

You need to integrate TWO OpenAI services to replace the current system:

**Replace current transcription with Realtime API:**
- Upgrade the existing "Start Recording" button to use OpenAI Realtime WebSocket
- Replace current real-time transcription display with Realtime API streaming
- Maintain the exact same UI components and user flow

**Replace current AI processing with Assistants API:**
- Upgrade "GPT Suggestions" to use Assistant context with patient history
- Replace SOAP note generation with Assistant-powered processing
- Upgrade "Draft Orders" creation to use Assistant intelligence
- Replace "CPT Codes & Diagnoses" with Assistant-based extraction

**The goal:** Keep the exact same interface but power it with modern APIs that provide better accuracy and patient context.

---
