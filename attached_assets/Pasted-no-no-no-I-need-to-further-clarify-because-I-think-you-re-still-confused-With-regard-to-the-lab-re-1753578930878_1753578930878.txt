no no no. I need to further clarify because I think you're still confused. With regard to the lab results and GPT reviews there are 2 types of GPT-generated reviews. The first one is already coded and prompted (and has been for some time). It's generated when the provider is first looking at the lab resutls and presses "review" and then "generate AI review". THIS AI review sometimes gets sent to the patient or the nurse as the initial opinion coming from the physician about the patient's lab results. Let's call this variable "docsthoughts". Docsthoughts can come from the doctor themselves who says (for example) "labs normal". Or they can be generated from the GPT and then edited by the doctor. Or they can be generated from the GPT and NOT edited, or whatever. ULtimately, they are approved by the doctor in some form or fashion. Docsthoughts get sent either to the patient directly, or to the nurse who will then call the patient. suppose the nurse calls the patient with the results. Let’s call that variable “nursetalk”. The nurse calls the patient and shares whatever docsthoughts contained, then the patient might have a question or opinion about it and so they tell the nurse their thoughts/opinions. Let’s call this variable “patientopinions”. This gets routed back to the nurse who handles the question and then closes the results encounter. In this particular scenario I can summarize it like this: docsthoughts-> nursetalk -> patientopinions -> nursetalk -> close. This entire journey from docsthoughts all the way to close is a type of conversation. GPT is supposed to summarize this conversation into it’s own “review”. Let’s call THAT review conversation_review. So now we have two entirely different “GPT reviews” that you’re probably confusing. There is the (potential) first review by GPT which is docsthoughts (I say POTENTIAL because the doc might not use GPT at all and might just type the note himself). Then there is the second review which is ALWAYS GPT which is we’re calling conservation_review. It’s conversation_review that should be displayed prominently in the review section below the lab results matrix. It’s a summary generated by GPT that explains the entire conversation that just happened concerning the lab results. An example of the conversation_review might be “MD advised increasing metformin to 1,000mg BID, pt refused, nurse documented”. Another example for the conversation_review might be, “doctor asked nurse to inform pt labs were normal, pt did not return call, letter sent”. This is entirely different than the docsthoughts, which might be generate for augmented by GPT but might not. Again, all of these variables I just made up are NOT part of our code. They are just examples to help me communicate this idea with you. 